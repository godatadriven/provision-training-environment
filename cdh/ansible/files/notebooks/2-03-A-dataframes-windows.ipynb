{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_root = '/user/centos/'\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.sql import Window, Row\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_heroes = spark.read.csv(dir_root + 'data/heroes.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_heroes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Compute the demeaned attack for each hero wrt other heroes in its role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_heroes_agg = (ddf_heroes\n",
    "                  .groupBy('role')\n",
    "                  .agg(sf.mean('attack').alias('mean_attack')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_heroes_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(ddf_heroes\n",
    " .join(ddf_heroes_agg, on = ['role'])\n",
    " .withColumn('demeaned_attack', sf.col('attack') - sf.col('mean_attack'))\n",
    " .show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 partitionBy()\n",
    "- add aggregation as column (cleaner)\n",
    "- partition into windows by variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/partitions.png\" width=\"40%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ddf_role = (ddf_heroes.withColumn('demeaned_attack', sf.col('attack') - sf.mean('attack').over(Window.partitionBy('role')))) \n",
    "ddf_role.show(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick question: how is partitionBy different (in result) from the groupby-join method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ddf_role.sort('_c0').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_role.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf_role.sort(sf.col('_c0').cast('Int')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 orderBy()\n",
    "- sliding window\n",
    "- orderby -> sorting\n",
    "- window functions: first, last etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp = spark.createDataFrame([Row(mid=1, month=1.0, temperature=3.0),\n",
    " Row(mid=2, month=1.0, temperature=6.0),\n",
    " Row(mid=3, month=2.0, temperature=4.0),\n",
    " Row(mid=4, month=3.0, temperature=8.0),\n",
    " Row(mid=5, month=3.0, temperature=9.0),\n",
    " Row(mid=6, month=3.0, temperature=8.0),\n",
    " Row(mid=7, month=3.0, temperature=12.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('mid')\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.3 rowsBetween()\n",
    "- specify size of window in terms of rows before and after a row in ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-sys.maxsize, sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('mid').rowsBetween(-sys.maxsize, 0)\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .withColumn('temperature_minus_last', sf.col('temperature') - sf.last('temperature').over(wspec)) # why all zero?\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.4 rowsBetween() vs rangeBetween()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rowsBetween: this row and the next row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('month').rowsBetween(0, 1)\n",
    "(ddf_temp\n",
    " .withColumn('window_start_mid', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end_mid', sf.last('mid').over(wspec))\n",
    " .withColumn('max_temp', sf.max('temperature').over(wspec))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "rangeBetween: this value and the next value (of the column specified in orderBy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('month').rangeBetween(0, 1)\n",
    "(ddf_temp\n",
    " .withColumn('window_start_mid', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end_mid', sf.last('mid').over(wspec))\n",
    " .withColumn('max_temp', sf.max('temperature').over(wspec))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.5 Expanding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('mid').rangeBetween(-sys.maxsize, 0)\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('mid')\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`orderBy(col)` without row specification is implicitly `orderBy(col).rangeBetween(-sys.maxsize, 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Rolling mean accross months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('month')\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### partitionBy AND orderBy\n",
    "Rolling means within each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wspec = Window.partitionBy('month').orderBy('mid').rowsBetween(-sys.maxsize, 0) # order of orderBy and partitionBy clause doesn't matter\n",
    "(ddf_temp\n",
    " .withColumn('mean_temp', sf.mean('temperature').over(wspec))\n",
    " .withColumn('window_start', sf.first('mid').over(wspec))\n",
    " .withColumn('window_end', sf.last('mid').over(wspec))\n",
    " .sort('mid')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.5 lead() and lag()\n",
    "- access specific rows before or after a row\n",
    "- can access data outside of window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wspec = Window.orderBy('mid')\n",
    "(ddf_temp\n",
    " .withColumn('prev_temp', sf.lag('temperature').over(wspec))\n",
    " .withColumn('next_in_two_temp', sf.lead('temperature', count=2).over(wspec)) # why last 2 null?\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Exercise A*\n",
    "2. Add a column with the average temperature of the month\n",
    "3. Compute the temperature delta with the previous measurement\n",
    "1. Exclude rows of months with an average temperature below 5 degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp = spark.createDataFrame([Row(mid=1, month=1.0, temperature=3.0),\n",
    " Row(mid=2, month=1.0, temperature=6.0),\n",
    " Row(mid=3, month=2.0, temperature=4.0),\n",
    " Row(mid=4, month=3.0, temperature=8.0),\n",
    " Row(mid=5, month=3.0, temperature=9.0),\n",
    " Row(mid=6, month=3.0, temperature=8.0),\n",
    " Row(mid=7, month=3.0, temperature=12.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Exercise B*\n",
    "1. Demean the flight delays partitioning by year;\n",
    "2. Demean the flight delays partitioning by year/carrier;\n",
    "3. For each year, find the carriers with the most flights cancelled;\n",
    "4. Same as 3., but normalize by number of flights;\n",
    "5. Per airline, find the airport with the most delays due to security reasons in a given year/month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_air = spark.read.parquet(dir_root + 'data/airlines.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Output: storing your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf_temp.write.saveAsTable('table_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sh hdfs dfs -ls /user/hive/warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp.write.save(path = 'ddf/temperature',\n",
    "               format = 'parquet', #json \n",
    "               mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sh hdfs dfs -ls /user/centos/ddf/temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp.coalesce(1).write.save(path = 'ddf/temperature_coalesce',\n",
    "               format = 'parquet', #json \n",
    "               mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!sh hdfs dfs -ls /user/centos/ddf/temperature_coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

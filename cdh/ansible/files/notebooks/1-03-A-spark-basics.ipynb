{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spark basics\n",
    "\n",
    "In this chapter we will cover the following topics:\n",
    "\n",
    "- What is an RDD?\n",
    "- RDD basics\n",
    "   - Operations\n",
    "   - Actions\n",
    "   - Lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RDD ( Resilient Distributed Dataset)\n",
    "\n",
    "- Resilient - if data in memory is lost, it can be recreated\n",
    "- Distributed - processed across the cluster\n",
    "- Dataset - initial data can come from a file or be created programatically\n",
    "\n",
    "\n",
    "__ RDD is the fundamental unit of data in Spark __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating an RDD\n",
    "\n",
    " - We can create a RDD in 3 ways:\n",
    "   1. Using existing data (for example: read from files).\n",
    "   2. By transforming another RDD.\n",
    "   3. Generating data in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Creating an RDD\n",
    "\n",
    "The spark context provides calls to create RDDs:\n",
    "\n",
    " - `sc.textFile(\"/some/hdfs-ish/path\")`<br>\n",
    "   This creates an RDD, where each item is a line from the text file(s).\n",
    "   In this cluster environment HDFS is the default for file locations. If you want to read from the local filesystem you need to specify the path as follows `sc.textFile(\"file:///some/fully/specified/path\")`\n",
    " - `rdd.doTransformation(transformationFunction)`<br>\n",
    "   Pseudo code\n",
    " - `sc.parallelize([\"An\", \"Example\", \"Collection\"])`<br>\n",
    "   This creates an RDD using the collection you supply. (This isn't 'big' data, but can be useful when doing things    like seeding machine-learning algorithms or testing functions when exploring data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RDD from files\n",
    "\n",
    "The `sc.textFile` method reads in the data line by line with the default lineseparator `\\n`. Every line in the file will become a record in the RDD.<br>\n",
    "\n",
    "But what about multiline data like JSON or XML?  \n",
    "\n",
    "For that the method `sc.wholeTextFiles(\"/some/directory\")` is available. This will create a RDD with the following structure:\n",
    "\n",
    "```\n",
    "(file1.json, {\"name\": \"Gerard\", \"id\": 123456, \"age\": 46})\n",
    "(file2.json, {\"name\": \"Michael\", \"id\": 534623, \"age\": 26})\n",
    "(file5.json, {\"name\": \"Ronald\", \"id\": 1344, \"age\": 16})\n",
    "(file8.json, {\"name\": \"Daisy\", \"id\": 34534})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transforming an RDD\n",
    "\n",
    "We also have many many ways of transforming RDDs to produce a new one. Some key transformations:\n",
    "\n",
    " - `map`\n",
    " - `filter`\n",
    " - `flatMap`\n",
    " - `sort`\n",
    " - `distinct`\n",
    " - `groupBy`\n",
    " - `intersection`\n",
    " \n",
    "The API documentation describes all these: there are many methods. Transformations are the ones that _return a RDD_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RDDs are Lazy\n",
    "\n",
    " - When we create an RDD, its content is _not_ evaluated.\n",
    " - Instead a _lineage_ is constructed: each RDD knows what parentRDD it depends on, and what it needs to do, but won't actually do anything until the content of the RDD is actually required.\n",
    " \n",
    "When is the content of the RDD actually required?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# RDD Actions\n",
    "\n",
    " - Actions trigger an RDD to evaluate its content, which is normally based on the lineage in a recursive manner.\n",
    " - These are normally methods on the RDD that _don't_ return a RDD.\n",
    " - Some examples include:\n",
    "   - `collect`\n",
    "   - `first`\n",
    "   - `take`\n",
    "   - `top`\n",
    "   - `count`\n",
    "   - `isEmpty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "spark = (\n",
    "    pyspark.sql.SparkSession.builder\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting it Togetherâ€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, \n",
    "                          12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
    "odd_numbers = numbers.filter(lambda n: n % 2 == 1)\n",
    "odd_numbers.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_numbers.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_numbers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_numbers.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is the content of `odd_numbers` evaluated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This lineage thing\n",
    "\n",
    "- Nothing happens until an action is called => lazy execution\n",
    "\n",
    "- RDD Lineage is a graph of all the parent RDDs of a RDD. It is built as a result of applying transformations to the RDD and creates a logical execution plan.\n",
    "\n",
    "- The data is not cached by default -> re-executing twice the same commands, actually executes all steps again\n",
    "\n",
    "- The lineage can be inspected with the toDebugString method of the RDD\n",
    "\n",
    "        RDD.toDebugString()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'(1) PythonRDD[4] at collect at <ipython-input-5-efa00ed215ae>:1 []\\n |  ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:475 []'\n"
     ]
    }
   ],
   "source": [
    "print(odd_numbers.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "In this chapter we covered:\n",
    "\n",
    "- RDD operations/actions/lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dir_root = os.getcwd() + '/'\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf = spark.createDataFrame([[np.nan, 'John'],\n",
    "                             [None, 'Michael'],\n",
    "                             [30., 'Andy'],\n",
    "                             [19., 'Justin'],\n",
    "                             [30., 'James Dr No From Russia with Love Bond']], \n",
    "                             schema = ['age', 'name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intermezzo: laziness in Spark\n",
    "- Transformations (lazy, Catalyst)\n",
    "    - filter\n",
    "    - select\n",
    "    - join\n",
    "    - etc. (most)\n",
    "\n",
    "\n",
    "- Actions (actual computation)\n",
    "    - count\n",
    "    - show\n",
    "    - head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick question: what would be a good moment to cache?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Functions\n",
    "- lots of functions (too many)\n",
    "- know the fundamentals\n",
    "- API Docs: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1 when -> otherwise\n",
    "2 ways of being Andy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(ddf\n",
    " .withColumn('is_andy', sf.col('name') == 'Andy')\n",
    " .withColumn('is_andy2', sf.when(sf.col('name') == 'Andy', True)\n",
    "                           .otherwise(False))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf\n",
    " .withColumn('whos_this', sf.when(sf.col('name') == 'Andy', 'Yup, Andy')\n",
    "                            .when(sf.col('name') == 'Justin', 'Justin here'))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2 isin()\n",
    "2 ways of being Andy or Justin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf\n",
    " .withColumn('is_andy_or_justin', (sf.col('name') == 'Andy') |\n",
    "                                  (sf.col('name') == 'Justin'))\n",
    " .withColumn('is_andy_or_justin2', sf.col('name').isin('Andy', 'Justin'))\n",
    " .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf = ddf.withColumn('is_teen', sf.col('age').isin(list(range(20))))\n",
    "ddf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4 lit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.withColumn('5', sf.lit(5))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.5 ~ (negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.withColumn('aint_no_teen', ~sf.col('is_teen'))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intermezzo: raw SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf.registerTempTable('ddf')\n",
    "(spark\n",
    " .sql(\"SELECT age, count(*) FROM ddf GROUP BY age\")\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.6 join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf1 = spark.createDataFrame([[1], [2]], schema=['a'])\n",
    "ddf1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf2 = spark.createDataFrame([[2], [3]], schema=['a'])\n",
    "ddf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf1.join(ddf2, on = ['a'], how = 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf1.join(ddf2, on = ddf1.a == ddf2.a).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.7 isNull() / isNotNull() and isnan()\n",
    "Other very useful functions are `isNull()` and `isNotNull()`. They're used like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.withColumn('imputed_age', sf.when(sf.col('age').isNull(), 40)\n",
    "                                 .otherwise(sf.col('age')))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.withColumn('imputed_age', sf.when(sf.isnan('age'), 40)\n",
    "                                 .otherwise(sf.col('age')))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.8 fillna()\n",
    "- fills both null and NaN\n",
    "- fills only 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf\n",
    " .fillna(40, subset='age')\n",
    " .show()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.9 dropna()\n",
    "- drops both null and NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf\n",
    " .groupBy('age')\n",
    " .count()\n",
    " .dropna(subset = 'age')\n",
    " .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.10 sample()\n",
    "- possible to take subset of data toPandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf_air = spark.read.load(dir_root + 'data/airlines.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_air.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf_air.sample(False, fraction=0.0002)\n",
    "        .select('year', 'month')\n",
    "        .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.11 distinct() / countDistinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.distinct()\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(ddf.agg(sf.countDistinct('age').alias('distinct_ages'))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.12 User defined functions (UDF)\n",
    "- executed in RDD-land\n",
    "- avoid where possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "slen = sf.udf(lambda s: len(s), IntegerType())\n",
    "\n",
    "(ddf.withColumn('name_length', slen(ddf.name))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Exercise*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "1. Explore the `ddf_air` DF, and count how many NaN's you have in each column;\n",
    "2. Fill the NaN with something that makes sense for each column.\n",
    "3. With a UDF, capture the state in the `airport_name` column (e.g. 'NY' in 'New York, NY: John F. Kennedy International') and\n",
    "4. make a new dataframe `ddf_states` with columns `airport, state`\n",
    "3. Remove duplicates from ddf_states (hint: lookup `drop_duplicates()` in the docs)\n",
    "3. Join `ddf_states` onto the original `ddf_air` \n",
    "7. add a column weather_condition that is \n",
    "```\n",
    "'rainy' if the `weather_delay` is greather than 1200\n",
    "'stormy' if in addition to this the arrival is diverted by more than 15 minutes\n",
    "'bright' otherwise\n",
    "```\n",
    "6. Split the DF into a train and test set sorted by time cols (hint: lookup `limit()` or `randomSplit()` in the docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ddf_air = spark.read.load(dir_root + 'data/airlines.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Columns mean:\n",
    "\n",
    "* `arr_flights`: flights arrived\n",
    "* `arr_del15`: flights delayed more than 15';\n",
    "* `carrier_ct`: delayed by carrier;\n",
    "* `weather_ct`: by weather;\n",
    "* `nas_ct`: by national aviation system;\n",
    "* `security_ct`: by security;\n",
    "* `late_aircraft_ct`: by late aircraft arrival;\n",
    "* `arr_cancelled`: cancelled;\n",
    "* `arr_diverted`: deverted;\n",
    "* `arr_delay`: total delay and then breakdown below;\n",
    "* `carrier_delay`;\n",
    "* `weather_delay`;\n",
    "* `nas_delay`;\n",
    "* `security_delay`;\n",
    "* `late_aircraft_delay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

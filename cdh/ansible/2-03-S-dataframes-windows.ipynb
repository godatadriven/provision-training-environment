{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_root = '/user/centos/'\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.sql import Window, Row\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ddf_temp = spark.createDataFrame([Row(mid=1, month=1.0, temperature=3.0),\n",
    " Row(mid=2, month=1.0, temperature=6.0),\n",
    " Row(mid=3, month=2.0, temperature=4.0),\n",
    " Row(mid=4, month=3.0, temperature=8.0),\n",
    " Row(mid=5, month=3.0, temperature=9.0),\n",
    " Row(mid=6, month=3.0, temperature=8.0),\n",
    " Row(mid=7, month=3.0, temperature=12.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### *Exercise A*\n",
    "2. Add a column with the average temperature of the month\n",
    "3. Compute the temperature delta with the previous measurement\n",
    "1. Exclude rows of months with an average temperature below 5 degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "wspec = Window.partitionBy('month')\n",
    "ddf_temp = ddf_temp.withColumn('mean_temp_month', sf.mean('temperature').over(wspec))\n",
    "ddf_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "wspec = Window.orderBy('mid')\n",
    "ddf_temp = ddf_temp.withColumn('temp_delta', sf.col('temperature') - sf.lag('temperature').over(wspec))\n",
    "ddf_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.\n",
    "ddf_temp.filter(sf.col('mean_temp_month') > 5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Exercise B*\n",
    "1. Demean the flight delays partitioning by year;\n",
    "2. Demean the flight delays partitioning by year/carrier;\n",
    "3. For each year, find the carriers with the most flights cancelled;\n",
    "4. Same as 3., but normalize by number of flights;\n",
    "5. Per airline, find the airport with the most delays due to security reasons in a given year/month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_air = spark.read.load(dir_root + 'data/airlines.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.\n",
    "window = (Window.partitionBy(ddf_air['year']))\n",
    "\n",
    "(ddf_air.dropna(subset='arr_delay')\n",
    "        .select('year', 'carrier', ddf_air['arr_delay'] - sf.avg('arr_delay').over(window))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "window = (Window.partitionBy(ddf_air['year'], ddf_air['carrier']))\n",
    "(ddf_air.dropna(subset='arr_delay')\n",
    "        .select('year', 'carrier', ddf_air['arr_delay'] - sf.avg('arr_delay').over(window))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "cancelled_ddf_air = (ddf_air.dropna(subset='arr_cancelled')\n",
    "                              .select('year', 'carrier', 'arr_cancelled')\n",
    "                              .groupby('year', 'carrier').agg({'arr_cancelled': 'sum'})\n",
    "                              .withColumnRenamed('sum(arr_cancelled)', 'cancelled'))\n",
    "\n",
    "window = (Window.partitionBy(cancelled_ddf_air['year'])).orderBy(cancelled_ddf_air['cancelled'].desc())\n",
    "ranked_c_ddf_air = cancelled_ddf_air.select('year', 'carrier', 'cancelled', sf.rank().over(window).alias('n'))\n",
    "\n",
    "ranked_c_ddf_air.filter(ranked_c_ddf_air['n'] == 1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "cancelled_ddf_air = (ddf_air.dropna(subset='arr_cancelled')\n",
    "                              .select('year', 'carrier', 'arr_cancelled', 'arr_flights')\n",
    "                              .groupby('year', 'carrier').agg({'arr_cancelled': 'sum', 'arr_flights': 'sum'})\n",
    "                              .withColumnRenamed('sum(arr_cancelled)', 'cancelled')\n",
    "                              .withColumnRenamed('sum(arr_flights)', 'flights')\n",
    "                              .selectExpr('year', 'carrier', 'cancelled/flights')\n",
    "                              .withColumnRenamed('(cancelled / flights)', 'cancelled_pct'))\n",
    "\n",
    "window = (Window.partitionBy(cancelled_ddf_air['year'])).orderBy(cancelled_ddf_air['cancelled_pct'].desc())\n",
    "ranked_c_ddf_air = cancelled_ddf_air.select('year', 'carrier', 'cancelled_pct', sf.rank().over(window).alias('n'))\n",
    "\n",
    "ranked_c_ddf_air.filter(ranked_c_ddf_air['n'] == 1).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Per airline, find the airport with the largest delay. Report the year and month in which this happens\n",
    "window = (Window.partitionBy(sf.col('carrier')).orderBy(sf.col('security_delay').desc()))\n",
    "sec = ddf_air.dropna(subset='security_delay').select('carrier', 'airport', 'security_delay', 'year', 'month', sf.rank().over(window).alias('n'))\n",
    "sec.filter(sec['n'] == 1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

- name: Check for Anaconda
  stat: path=/anaconda/bin/conda
  register: anaconda_present

- name: fail if anaconda is not present
  fail: msg="The master node should have Anaconda. Make sure the initialization-action has run! (install_conda.sh)"
  when: anaconda_present.stat.exists == False

 - name: Update conda
   shell: "/anaconda/bin/conda update conda --quiet -y"

- name: Default enable the 'll'-alias for new user profiles.
  lineinfile:
    dest: /etc/skel/.bashrc
    state: present
    regexp: '^#alias ll.*'
    insertafter: '^#some more ls aliases'
    line: "alias ll='ls -lhA'"

- name: install packages
  apt:
    name: "{{packages}}"
    state: present
  vars:
    packages:
      - build-essential
      - libfreetype6-dev
      - blt-dev
      - pkg-config
      - libssl1.1
      - sudo

- name: place requirements
  template:
    src: requirements.txt
    dest: "/tmp/requirements.txt"

- name: remove notebooks tmp folder
  become: true
  become_user: root
  file:
    state: absent
    path: "{{ notebooks_tmp_folder }}"

- name: Creates notebooks folder directory
  file:
      path: "{{ notebooks_tmp_folder }}"
      state: directory

- name: remove notebooks folder
  file:
    state: absent
    path: "{{ notebooks_folder }}"

- name: Creates notebooks folder directory
  file:
      path: "{{ item }}"
      state: directory
  with_items:
    - "{{ notebooks_folder }}"
    - "{{ notebooks_folder }}/data"
    - "{{ notebooks_tmp_folder }}/notebooks"
    - "{{ notebooks_tmp_folder }}/answers"

- name: Check that the main user exists
  stat:
    path: /home/{{ deployer }}
  register: user_home

- name: Make sure we have a 'wheel' group
  group:
    name: wheel
    state: present
  when: user_home.stat.exists == False

- name: Allow 'wheel' group to have passwordless sudo
  lineinfile:
    dest: /etc/sudoers
    state: present
    regexp: '^%wheel'
    line: '%wheel ALL=(ALL) NOPASSWD: ALL'
  when: user_home.stat.exists == False

- name: Add sudoers deployer to wheel group
  user: name="{{ deployer }}" groups=wheel append=yes state=present createhome=yes
  when: user_home.stat.exists == False

- name: Make the deployer user not require tty to allow user-switching for creating virtual-envs
  template: src=sudoers_no_tty.j2 dest=/etc/sudoers.d/sudoers_no_tty

- name: place notebooks
  synchronize:
    src: files/notebooks/
    dest: "{{ notebooks_tmp_folder }}/notebooks"

- name: place answers
  synchronize:
    src: files/answers/
    dest: "{{ notebooks_tmp_folder }}/answers/"

- name: Make sure the users exists
  user:
    name: "{{ item.name }}"
    shell: /bin/bash
    append: yes
  with_items: "{{ users }}"

- name: The user must be owner of its own home-dir
  file: path=/home/{{ item.name }}/ state=directory owner={{ item.name }} group={{ item.name }} mode=0775
  with_items: "{{ users }}"

- name: mkdir .jupyter for every user
  file: path=/home/{{ item.name }}/.jupyter state=directory owner={{ item.name }} group={{ item.name }} mode=0755
  with_items: "{{ users }}"

- name: mkdir .conda for every user
  file: path=/home/{{ item.name }}/.conda state=directory owner={{ item.name }} group={{ item.name }} recurse=yes mode=0775
  with_items: "{{ users }}"

- name: place jupyter file for every user
  template: src=jupyter_notebook_config.py dest=/home/{{ item.name }}/.jupyter owner={{ item.name }}
  with_items: "{{ users }}"

- name: mkdirs for every user
  file: path={{notebooks_folder}}/{{ item.name }} state=directory owner={{ item.name }} group={{ item.name }} mode=0777
  with_items: "{{ users }}"

# We could also use `sync` to update or overwrite and delete files.
- name: copy notebooks and answers for every user
  shell: /bin/cp -R {{ notebooks_tmp_folder }}/* {{ notebooks_folder }}/{{ item.name }}/
  with_items: "{{ users }}"

- name: set ownership for notebooks
  file: path="{{ notebooks_folder }}/{{ item.name }}" group="{{ item.name }}" owner="{{ item.name }}" recurse=yes
  with_items: "{{ users }}"

- name: Copy environment specs
  template: src=environment.yml dest=/tmp/{{ item.name }}-environment.yml mode=755
  with_items: "{{ users }}"

- name: create conda env-dir for each user
  file:
    path: "/anaconda/envs/{{ item.env }}"
    state: directory
    owner: "{{ item.name }}"
    group: "{{ item.name }}"
  with_items: "{{ users }}"


# I have tried a lot of options to create a Conda-env per user.
# Conda creates various soft/hard/symlinks in each env.
# If you recursively modify access, the last user is applied to those symlinked-files and stuff breaks...
- name: Create user specific virtual conda environment
  shell: "sudo su {{ item.name }} -c '/anaconda/bin/conda env create -f /tmp/{{ item.name }}-environment.yml -p /anaconda/envs/{{ item.env }}'"
  args:
    creates: "/anaconda/envs/{{ item.env }}/bin"
  with_items: "{{ users }}"

- name: Get dataset
  unarchive:
    src: https://storage.googleapis.com/gdd-trainings-bucket/ds-spark-data.zip
    remote_src: yes
    dest: "{{ notebooks_folder }}/data"
    creates: "{{ notebooks_folder }}/data/heroes.csv"

- name: And the (small 1Mb) Movielens dataset
  src: http://files.grouplens.org/datasets/movielens/ml-latest-small.zip
  remote_src: yes
  dest: "{{ notebooks_folder }}/data"
  creates: "{{ notebooks_folder }}/data/ml-latest-small/movies.csv"

- name: And also the large (220Mb) Movielens dataset
  src: http://files.grouplens.org/datasets/movielens/ml-latest.zip
  remote_src: yes
  dest: "{{ notebooks_folder }}/data"
  creates: "{{ notebooks_folder }}/data/ml-latest/movies.csv"

- name: Copy all datasets to HDFS too
  shell: hdfs dfs -put -f "{{ notebooks_folder }}/data" /tmp/

- name: Copy jupyter start script
  template:
    src: start-jupyter.sh
    dest: "/anaconda/envs/{{ item.env }}"
    group: "{{ item.name }}"
    owner: "{{ item.name }}"
    mode: 0775
  with_items: "{{ users }}"

- name: Try to stop all jupyter processes
  shell: pkill jupyter
  ignore_errors: yes

- name: Start jupyter
  shell: "nohup sudo -u {{item.name}} /anaconda/envs/{{ item.env }}/start-jupyter.sh >> /tmp/{{ item.name }}-jupyter.log &"
  with_items: "{{ users }}"

- name: Check that Spark conf is present
  stat:
    path: /usr/lib/spark/conf
  register: spark_conf

- name: place spark defaults
  template: src=spark-defaults.conf dest=/tmp/spark-defaults.conf
  when: spark_conf.stat.exists == True

- name: get spark default contents
  shell: cat /tmp/spark-defaults.conf
  register: data
  when: spark_conf.stat.exists == True

- name: insert/update configuration using a local file
  blockinfile:
    dest: "/usr/lib/spark/conf/spark-defaults.conf"
    block: |
      {{ data.stdout }}
  when: spark_conf.stat.exists == True

- name: replace number of executors
  lineinfile:
     dest: "/usr/lib/spark/conf/spark-defaults.conf"
     regexp: 'spark\.executor\.instances'
     line: 'spark.executor.instances 2'
  when: spark_conf.stat.exists == True

- name: replace number of dynamic executors
  lineinfile:
     dest: "/usr/lib/spark/conf/spark-defaults.conf"
     regexp: 'dynamicAllocation\.maxExecutors'
     line: 'spark.dynamicAllocation.maxExecutors 2'
  when: spark_conf.stat.exists == True

- name: replace number of dynamic executors
  lineinfile:
     dest: "/usr/lib/spark/conf/spark-defaults.conf"
     regexp: 'port\.maxRetries'
     line: 'spark.port.maxRetries 200'
  when: spark_conf.stat.exists == True

- name: set SPARK_HOME
  lineinfile: dest=/etc/profile regexp="^export SPARK_HOME=" line="export SPARK_HOME=/usr/lib/spark"
  when: spark_conf.stat.exists == True
